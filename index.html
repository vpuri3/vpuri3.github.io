<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/poole_hyde.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } </style> <link rel=icon  href="/assets/favicon.png"> <title>Vedant Puri</title> <div class=sidebar > <div class="container sidebar-sticky"> <div class=sidebar-about > <h1><a href="/">VP</a></h1> <p class=lead >Vedant Puri</p> </div> <nav class=sidebar-nav > <a class="sidebar-nav-item active" href="/">Home</a> <a class="sidebar-nav-item " href="/thoughts/">Thoughts</a> <a class="sidebar-nav-item " href="/work/">Work</a> </nav> <p>&copy; Vedant Puri.</p> </div> </div> <div class="content container"> <div class=franklin-content ><h1 id=vedant_puri ><a href="#vedant_puri" class=header-anchor >Vedant Puri</a></h1> <p>PhD Candidate, Carnegie Mellon University Efficient Transformer Architectures | Scientific Machine Learning</p> <p>I design scalable transformer architectures grounded in numerical methods. My recent work introduces FLARE, a unified low-rank attention mechanism that scales to million-token problems on a single GPU. My background spans HPC, PDE solvers, and scientific computing.</p> <h2 id=featured_work ><a href="#featured_work" class=header-anchor >Featured Work</a></h2> <h3 id=flare_-_fast_low-rank_attention_routing_engine ><a href="#flare_-_fast_low-rank_attention_routing_engine" class=header-anchor >FLARE - Fast Low-Rank Attention Routing Engine</a></h3> <ul> <li><p>Unified low-rank reformulation of self-attention</p> <li><p>O&#40;NM&#41; memory scaling</p> <li><p>Scales to 1M tokens on a single GPU</p> <li><p>Benchmarked on PDE, NLP, and vision tasks</p> </ul> <p><a href="https://huggingface.co/papers/2508.12594">Paper</a> | <a href="https://github.com/vpuri3/FLARE.py">Code</a> | <a href="http://arxiv.org/abs/2508.12594">arXiv</a></p> <p><img src="https://raw.githubusercontent.com/vpuri3/FLARE.py/master/figs/time_memory_bwd.png" alt="" /></p> <h3 id=snf-rom ><a href="#snf-rom" class=header-anchor >SNF-ROM</a></h3> <p>SNF-ROM is a projection-based nonlinear reduced-order model using smooth neural fields for advection-dominated PDEs.</p> <p><a href="https://arxiv.org/abs/2405.14890">Journal of Computational Physics paper</a> | <a href="https://github.com/vpuri3/NeuralROMs.jl">Code</a></p> <h2 id=research_themes ><a href="#research_themes" class=header-anchor >Research Themes</a></h2> <ul> <li><p>Efficient attention and low-rank transformers</p> <li><p>Neural operators and PDE surrogates</p> <li><p>Numerical methods for ML architectures</p> <li><p>Scientific computing at scale</p> </ul> <h2 id=open_source ><a href="#open_source" class=header-anchor >Open Source</a></h2> <h3 id=flare ><a href="#flare" class=header-anchor >FLARE</a></h3> <p><a href="https://github.com/vpuri3/FLARE.py">FLARE.py</a>: Fast Low-rank Attention Routing Engine for scalable transformer attention.</p> <h3 id=julia_open_source_tools ><a href="#julia_open_source_tools" class=header-anchor >Julia Open Source Tools</a></h3> <ul> <li><p><a href="https://github.com/vpuri3/SciMLOperators.jl">SciMLOperators.jl</a>: operator abstractions for SciML and PDE workflows</p> <li><p><a href="https://github.com/vpuri3/LinearSolve.jl">LinearSolve.jl</a>: linear solver interface for scientific machine learning</p> </ul> <p>Additional Julia repos I have worked on include <a href="https://github.com/vpuri3/OrdinaryDiffEq.jl">OrdinaryDiffEq.jl</a>, <a href="https://github.com/vpuri3/NonlinearSolve.jl">NonlinearSolve.jl</a>, <a href="https://github.com/vpuri3/Optimization.jl">Optimization.jl</a>, <a href="https://github.com/vpuri3/SciMLBase.jl">SciMLBase.jl</a>, <a href="https://github.com/vpuri3/SciMLSensitivity.jl">SciMLSensitivity.jl</a>, <a href="https://github.com/vpuri3/DiffEqFlux.jl">DiffEqFlux.jl</a>, <a href="https://github.com/vpuri3/StochasticDiffEq.jl">StochasticDiffEq.jl</a>, and <a href="https://github.com/vpuri3/DiffEqBase.jl">DiffEqBase.jl</a>.</p> <h3 id=kolmogorovarnoldjl ><a href="#kolmogorovarnoldjl" class=header-anchor >KolmogorovArnold.jl</a></h3> <p><a href="https://github.com/vpuri3/KolmogorovArnold.jl">KolmogorovArnold.jl</a>: Julia implementation of Kolmogorov-Arnold Networks with custom gradients for faster training.</p> <h3 id=nektools ><a href="#nektools" class=header-anchor >NekTools</a></h3> <p><a href="https://github.com/vpuri3/NekTools">NekTools</a>: FORTRAN 77 utilities for turbulence statistics and post-processing in NEK5000.</p> <h2 id=blog ><a href="#blog" class=header-anchor >Blog</a></h2> <p>Long-form background, older project descriptions, and non-ML writing are archived here:</p> <ul> <li><p><a href="/work/">Work archive</a></p> <li><p><a href="/thoughts/">Thoughts archive</a></p> </ul> <p>Planned technical post:</p> <ul> <li><p>How to scale attention to 1M tokens on a single GPU</p> </ul> <div class=page-foot > <div class=copyright > &copy; Vedant Puri. Last modified: February 13, 2026. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div>