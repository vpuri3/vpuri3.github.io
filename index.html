<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Vedant Puri | Efficient Transformer Architectures</title>
  <meta name="description" content="Vedant Puri, PhD Candidate at CMU. Efficient transformer architectures, scientific machine learning, and numerical methods.">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Manrope:wght@400;500;700;800&family=IBM+Plex+Mono:wght@400;500&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <header class="topbar">
    <div class="wrap topbar-inner">
      <a class="brand" href="#top">Vedant Puri</a>
      <nav class="nav">
        <a href="#featured">Featured</a>
        <a href="#themes">Themes</a>
        <a href="#open-source">Open Source</a>
        <a href="#blog">Blog</a>
      </nav>
    </div>
  </header>

  <main id="top">
    <section class="hero wrap reveal">
      <p class="kicker">PhD Candidate, Carnegie Mellon University</p>
      <h1>Efficient Transformer Architectures for Scientific Machine Learning</h1>
      <p class="summary">I design scalable transformer architectures grounded in numerical methods.</p>
      <p class="summary">My recent work introduces FLARE, a unified low-rank attention mechanism that scales to million-token problems on a single GPU.</p>
      <p class="summary">My background spans HPC, PDE solvers, and scientific computing.</p>
      <div class="cta-row">
        <a class="btn primary" href="https://github.com/vpuri3/FLARE.py">View FLARE</a>
        <a class="btn" href="https://github.com/vpuri3/vpCV/raw/master/vpCV.pdf">CV</a>
      </div>
    </section>

    <section class="wrap reveal" id="featured">
      <h2>Featured Work</h2>
      <article class="card featured-card">
        <div class="card-header">
          <h3>FLARE - Fast Low-Rank Attention Routing Engine</h3>
          <span class="tag">Flagship</span>
        </div>
        <ul>
          <li>Unified low-rank reformulation of self-attention</li>
          <li>O(NM) memory scaling</li>
          <li>Scales to 1M tokens on a single GPU</li>
          <li>Benchmarked on PDE, NLP, and vision tasks</li>
        </ul>
        <p class="links">
          <a href="https://huggingface.co/papers/2508.12594">Paper</a>
          <a href="https://github.com/vpuri3/FLARE.py">Code</a>
          <a href="http://arxiv.org/abs/2508.12594">arXiv</a>
        </p>
        <img src="https://raw.githubusercontent.com/vpuri3/FLARE.py/master/figs/time_memory_bwd.png" alt="FLARE scaling plot">
      </article>

      <article class="card featured-card">
        <h3>SNF-ROM</h3>
        <p>SNF-ROM is a projection-based nonlinear reduced-order modeling framework with smooth neural fields for advection-dominated PDEs.</p>
        <ul>
          <li>Combines projection-based ROM with continuous neural field representations</li>
          <li>Targets challenging transport-dominated PDE regimes</li>
          <li>Implemented in Julia with experiment suites for 1D and 2D advection and Burgers systems</li>
          <li>Includes reproducible pipelines for dataset generation, training, and model comparison</li>
        </ul>
        <p class="links">
          <a href="https://vpuri3.github.io/NeuralROMs.jl/dev/">Project page</a>
          <a href="https://arxiv.org/abs/2405.14890">JCP paper</a>
          <a href="https://github.com/vpuri3/NeuralROMs.jl">Code</a>
          <a href="https://slides.com/vedantpuri/snf-rom-wccm2024">Slides</a>
          <a href="https://youtu.be/zio-_89DJ0g?si=sDVE1c0xJqzVi8bm">Talk</a>
        </p>
        <img src="assets/snfrom-online-stage.png" alt="SNF-ROM online stage architecture">
      </article>
    </section>

    <section class="wrap reveal" id="themes">
      <h2>Research Themes</h2>
      <div class="grid two-up">
        <div class="card"><p>Efficient attention and low-rank transformers</p></div>
        <div class="card"><p>Neural operators and PDE surrogates</p></div>
        <div class="card"><p>Numerical methods for ML architectures</p></div>
        <div class="card"><p>Scientific computing at scale</p></div>
      </div>
    </section>

    <section class="wrap reveal" id="open-source">
      <h2>Open Source</h2>
      <div class="stack">
        <article class="card">
          <h3>FLARE</h3>
          <p><a href="https://github.com/vpuri3/FLARE.py">FLARE.py</a>: Fast Low-rank Attention Routing Engine for scalable transformer attention.</p>
        </article>

        <article class="card">
          <h3>Julia Open Source Tools</h3>
          <ul>
            <li><a href="https://github.com/vpuri3/SciMLOperators.jl">SciMLOperators.jl</a>: operator abstractions for SciML and PDE workflows</li>
            <li><a href="https://github.com/vpuri3/LinearSolve.jl">LinearSolve.jl</a>: linear solver interface for scientific machine learning</li>
          </ul>
          <p>Additional Julia repos: <a href="https://github.com/vpuri3/OrdinaryDiffEq.jl">OrdinaryDiffEq.jl</a>, <a href="https://github.com/vpuri3/NonlinearSolve.jl">NonlinearSolve.jl</a>, <a href="https://github.com/vpuri3/Optimization.jl">Optimization.jl</a>, <a href="https://github.com/vpuri3/SciMLBase.jl">SciMLBase.jl</a>, <a href="https://github.com/vpuri3/SciMLSensitivity.jl">SciMLSensitivity.jl</a>, <a href="https://github.com/vpuri3/DiffEqFlux.jl">DiffEqFlux.jl</a>, <a href="https://github.com/vpuri3/StochasticDiffEq.jl">StochasticDiffEq.jl</a>, <a href="https://github.com/vpuri3/DiffEqBase.jl">DiffEqBase.jl</a>.</p>
        </article>

        <article class="card">
          <h3>KolmogorovArnold.jl</h3>
          <p><a href="https://github.com/vpuri3/KolmogorovArnold.jl">KolmogorovArnold.jl</a>: Julia implementation of Kolmogorov-Arnold Networks with custom gradients for faster training.</p>
        </article>

        <article class="card">
          <h3>NekTools</h3>
          <p><a href="https://github.com/vpuri3/NekTools">NekTools</a>: FORTRAN 77 utilities for turbulence statistics and post-processing in NEK5000.</p>
        </article>
      </div>
    </section>

    <section class="wrap reveal" id="blog">
      <h2>Blog</h2>
      <p>Long-form background, older project descriptions, and non-ML writing:</p>
      <ul>
        <li><a href="/work.html">Work archive</a></li>
        <li><a href="/thoughts.html">Thoughts archive</a></li>
      </ul>
      <p>Planned technical post: <strong>How to scale attention to 1M tokens on a single GPU</strong>.</p>
    </section>
  </main>

  <footer class="wrap footer">
    <p>Vedant Puri</p>
    <p><a href="https://github.com/vpuri3">GitHub</a> <span class="sep">|</span> <a href="https://www.linkedin.com/in/vpuri3/">LinkedIn</a> <span class="sep">|</span> <a href="mailto:vedantpuri@cmu.edu">Email</a></p>
  </footer>

  <script>
    const observer = new IntersectionObserver((entries) => {
      entries.forEach((entry) => {
        if (entry.isIntersecting) entry.target.classList.add("show");
      });
    }, { threshold: 0.12 });
    document.querySelectorAll(".reveal").forEach((el) => observer.observe(el));
  </script>
</body>
</html>
